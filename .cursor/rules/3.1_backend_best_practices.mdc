---
description: Best practices for backend development in the linkBD application
globs: apps/server/**
alwaysApply: false
---
# Backend Best Practices

Follow these best practices when working on the linkBD backend to ensure code quality, type safety, and maintainability.

## 1. Schema-First Database Approach with Drizzle

**CRITICAL**: Always define database schema changes, indexes, and constraints in the Drizzle schema file FIRST before implementing any data access logic.

### Why This Matters
- Drizzle generates optimized migrations automatically from schema changes
- Schema serves as single source of truth for database structure
- Type safety across the entire application from database to frontend
- Proper indexing defined at schema level ensures optimal performance
- Avoids manual migration scripts that can become inconsistent

### ✅ Correct Schema-First Approach
```typescript
// 1. FIRST: Define schema changes in src/db/schema.ts
export const posts = pgTable('posts', {
  id: text('id').primaryKey(),
  content: text('content').notNull(),
  visibility: text('visibility').notNull().default('public'),
  createdAt: timestamp('created_at').defaultNow().notNull(),
  likesCount: integer('likes_count').notNull().default(0),
}, (table) => ({
  // Define indexes directly in schema for pagination
  visibilityCreatedAtIdx: index('idx_posts_visibility_created_at')
    .on(table.visibility, table.createdAt.desc()),
  createdAtIdx: index('idx_posts_created_at')
    .on(table.createdAt.desc()),
  likesCountIdx: index('idx_posts_likes_count')
    .on(table.likesCount.desc()),
}));

// 2. THEN: Tell the user to run the mgiration
```

### ❌ Incorrect Approaches
```typescript
// ❌ NEVER create manual migration files for schema changes
// ❌ NEVER add indexes via raw SQL when they should be in schema
// ❌ NEVER implement data access without schema definition first

// Wrong: Manual migration file
async function addIndexes() {
  await db.execute(sql`CREATE INDEX ...`); // ❌ Should be in schema
}
```

### Database Index Best Practices
```typescript
// Pagination indexes (essential for performance)
visibilityCreatedAtIdx: index('idx_posts_visibility_created_at')
  .on(table.visibility, table.createdAt.desc()),

// User-specific queries
userVisibilityIdx: index('idx_posts_user_visibility')
  .on(table.userId, table.visibility),

// Composite indexes for complex queries
userVisibilityCreatedAtIdx: index('idx_posts_user_visibility_created_at')
  .on(table.userId, table.visibility, table.createdAt.desc()),
```

### Schema Change Workflow
1. **Schema Definition**: Add/modify tables in `schema.ts`
2. **Index Planning**: Define indexes for expected query patterns
3. **Generate Migration**: `npm run db:generate`
4. **Review Migration**: Check generated SQL before applying
5. **Apply Migration**: `npm run db:migrate`
6. **Implement Logic**: Write models and routes using new schema

### When to Use Custom Migrations
Only use custom migration scripts in `src/db/admin/migrations/` for:
- **Data transformations** (not schema changes)
- **One-time data fixes** or cleanup
- **Complex data seeding** that can't be handled by schema defaults
- **Multi-step data operations** that require business logic

## 2. Hono RPC Method Chaining with Documentation

**CRITICAL**: All route handlers MUST use method chaining to maintain end-to-end type safety AND include documentation comments above each endpoint.

### Why This Matters
- TypeScript can only infer route types when methods are chained in a single declaration
- Breaking the chain means the frontend loses IntelliSense and type checking
- The RPC system depends on continuous method chaining to generate proper types
- Clear documentation improves code maintainability and team collaboration

### ✅ Correct Implementation
```typescript
// Always chain methods with documentation comments
const posts = new Hono()
  // Get all posts for the authenticated user
  .get('/', async (c) => { /* handler */ })
  
  // Create a new post with validation
  .post('/', async (c) => { /* handler */ })
  
  // Get a specific post by ID
  .get('/:id', async (c) => { /* handler */ })
  
  // Update an existing post
  .put('/:id', async (c) => { /* handler */ })
  
  // Like/unlike a post
  .patch('/:id/like', async (c) => { /* handler */ })
  
  // Delete a post
  .delete('/:id', async (c) => { /* handler */ })

export default posts
```

### ❌ Incorrect Implementation
```typescript
// NEVER break the chain like this
const posts = new Hono()
posts.get('/', handler)  // ❌ Breaks type inference
posts.post('/', handler) // ❌ Types are lost

// NEVER omit documentation
const posts = new Hono()
  .get('/', async (c) => { /* handler */ })     // ❌ No documentation
  .post('/', async (c) => { /* handler */ })    // ❌ Unclear purpose
```

### Main App Setup
```typescript
// In index.ts - chain all application routes and export AppType
const routes = app
  .route('/api/user', userRoutes)
  .route('/api/posts', postsRoutes)
  .route('/api/jobs', jobsRoutes)

export type AppType = typeof routes  // Critical for frontend type safety
```

## 3. Model Functions vs Route Handlers

### Model Functions (in `models/` directory)
- Handle all database operations and business logic
- Return raw data or throw errors
- Keep routes thin and focused on HTTP concerns

### Route Handlers (in `routes/` directory)
- Handle HTTP request/response only
- Call model functions for data operations
- Format responses with proper status codes

### Example
```typescript
// models/posts.ts
export async function getPostById(postId: string, userId: string) {
  const results = await db
    .select()
    .from(posts)
    .where(and(
      eq(posts.id, postId),
      eq(posts.userId, userId)
    ));
  
  return results[0] || null;
}

// routes/posts.ts
.get('/:id', authMiddleware, async (c) => {
  const user = c.get('user');
  const postId = c.req.param('id');
  
  const post = await postModel.getPostById(postId, user.id);
  
  if (!post) {
    return c.json({ error: 'Post not found' }, 404);
  }
  
  return c.json(post);
})
``` 

## 4. Custom Data Migration Standards

We've already established to use drizzle for schema changes where the orm is used. However, for complex migrations, we can use the custom migration scripts in `src/db/admin/migrations/`.

**STANDARD**: All custom data migration scripts in `src/db/admin/migrations/` MUST follow a standardized naming convention and structure.

### Naming Convention
- **Format**: `{sequence}_{feature-name}{phase}.ts`
- **Sequence**: 3-digit zero-padded number (001, 002, 003, etc.)
- **Feature Name**: Descriptive kebab-case name of the feature being migrated
- **Phase**: Optional numeric suffix for multi-phase migrations

### ✅ Correct Migration Names
```
001_organization-posts-phase1.ts
002_user-profile-data.ts
003_storage-cleanup.ts
004_organization-posts-phase2.ts
005_better-auth-migration.ts
```

### ❌ Incorrect Migration Names
```
migration-organization-posts.ts           // ❌ No sequence number
1-org-posts.ts                           // ❌ Not zero-padded
organization_posts_migration.ts          // ❌ Underscores instead of hyphens
001-organizationPosts.ts                 // ❌ CamelCase instead of kebab-case
```

### Migration File Structure
```typescript
/**
 * Migration Script - {Phase}: {Feature Name}
 * 
 * Brief description of what this migration does and why.
 * 
 * Prerequisites:
 * - List any schema changes required first
 * - Database backup recommendations
 * 
 * Usage:
 * tsx {filename}.ts           // Run migration
 * tsx {filename}.ts --rollback // Rollback migration  
 * tsx {filename}.ts --help     // Show help
 */

import { sql, and, isNotNull } from 'drizzle-orm';
import { db } from '../../index';
import { tableName } from '../../schema';
import { log } from '../cli/utils/logger';
import type { NodePgDatabase } from 'drizzle-orm/node-postgres';
import * as schema from '../../schema';

async function migrateFeatureName() {
  log.title('Starting migration: {Feature Name} {Phase}');
  
  try {
    // Step 1: Pre-migration validation
    // Step 2: Execute migration in transaction
    // Step 3: Post-migration verification
    // Step 4: Summary logging
  } catch (error) {
    log.error(`Migration failed: ${error}`);
    process.exit(1);
  }
}

async function rollbackMigration() {
  log.title('Starting rollback: {Feature Name} {Phase}');
  // Rollback implementation
}

// Command line handling
const command = process.argv[2];
if (command === '--rollback') {
  rollbackMigration().catch(handleError);
} else if (command === '--help') {
  showHelp();
} else {
  migrateFeatureName().catch(handleError);
}
```

### Migration Requirements
1. **Transaction Safety**: All data modifications MUST be wrapped in transactions
2. **Rollback Support**: Every migration MUST include a rollback function
3. **Validation**: Include pre and post-migration validation checks
4. **Logging**: Use the admin CLI logger for consistent output
5. **Error Handling**: Proper error handling with process.exit(1) on failure
6. **Documentation**: Clear header comments explaining purpose and usage

### Integration with Admin CLI
- Migrations are separate from Drizzle schema migrations
- Use existing `db` instance from `../../index`
- Follow same patterns as other admin tools
- Include help command for usage documentation